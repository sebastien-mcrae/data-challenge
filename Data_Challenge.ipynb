{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F1RkWakdlUT6"
      ],
      "authorship_tag": "ABX9TyPtd6buJpvdcMCdTXxj9fsd"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_nBEKK3W_a_"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTd8E9T7XBvr"
      },
      "source": [
        "This notebook is a simplified version of the one used for the \"NLP applied to judicial decisions parsing\" challenge of the student competition organized each year by the Data team of the Ecole Normale Supérieure of Paris in partnership with the Collège de France.\n",
        "\n",
        "* Details: https://challengedata.ens.fr/challenges/24\n",
        "* Leaderboard: https://challengedata.ens.fr/leaderboard/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7RSjkIYKgR"
      },
      "source": [
        "## Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDJi2TfrYL-T"
      },
      "source": [
        "When a trial is over, a summary of the trial is published with all the important information dealing with the case that have just been judged.\n",
        "This document is called jurisprudence in French.\n",
        "\n",
        "In the case of a trial between a victim and an insurer, this document contains all the circumstances, and the medical and financial data from the first injuries to the final amounts of indemnisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZUC4R0yYObW"
      },
      "source": [
        "## Challenge goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR4jk6rFYQH_"
      },
      "source": [
        "We have “jurisprudence” data as text files and we want to build an algorithm to automate the extraction of the relevant information.\n",
        "In this challenge, we want to extract from \"jurisprudence\" the date of the accident and the date of the stabilization of the injuries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1RkWakdlUT6"
      },
      "source": [
        "## Let's load our data in a nice Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_qFQRgulP06"
      },
      "source": [
        "!unzip -q train_folder_predilex.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcKIgxYVPiNe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "x_train_ids = pd.read_csv('train_folder/x_train_ids.csv', index_col='ID')\n",
        "doc_labels = pd.read_csv('Y_train_predilex.csv', index_col='ID')\n",
        "doc_labels.columns = ['gender', 'accident_date', 'stabilization_date']\n",
        "\n",
        "text_files = {}\n",
        "for index, filename in x_train_ids['filename'].iteritems():\n",
        "  with open(f'train_folder/txt_files/{filename}') as file:\n",
        "      raw_content = file.read()\n",
        "      cleaned_content = raw_content.replace('...','').replace(' ;','.')\n",
        "      text_files[index] = \" \".join(cleaned_content.split())\n",
        "\n",
        "df_text_files = pd.DataFrame.from_dict(text_files, orient='index', columns=['text'])\n",
        "\n",
        "df_docs = pd.concat([doc_labels,df_text_files], axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PQ1ioLfP9Ta"
      },
      "source": [
        "df_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsQ1s5lBlfzY"
      },
      "source": [
        "## Now we split our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onaav2UUCoDL"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_docs_train, df_docs_test = train_test_split(df_docs, test_size=0.2, random_state=42)\n",
        "df_docs_train, df_docs_test = df_docs_train.copy(), df_docs_test.copy()\n",
        "\n",
        "print(f'Number of documents in the train set: {len(df_docs_train)}')\n",
        "print(f'Number of documents in the test set: {len(df_docs_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKIwS0agIT9D"
      },
      "source": [
        "## Let's train our own sentence tokenizer! (On the train set) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3VzV2MIIS84"
      },
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "\n",
        "train_tokenizer = ' '.join(df_docs_train.text)\n",
        "\n",
        "sent_tokenizer = PunktSentenceTokenizer(train_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj2BaoRxllrr"
      },
      "source": [
        "## Let's split our documents into sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olc0cj_P-pfU"
      },
      "source": [
        "df_docs_train['sentences'] = df_docs_train.apply(lambda row: sent_tokenizer.tokenize(row['text']),axis=1)\n",
        "df_docs_train.index.name = 'doc_id'\n",
        "df_docs_train.sort_index(inplace=True)\n",
        "df_docs_test['sentences'] = df_docs_test.apply(lambda row: sent_tokenizer.tokenize(row['text']),axis=1)\n",
        "df_docs_test.index.name = 'doc_id'\n",
        "df_docs_test.sort_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlCXDM4Am9b2"
      },
      "source": [
        "## Now we extract the context around each dates and we label it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekhqftASb1tl"
      },
      "source": [
        "import re\n",
        "from preprocessing import Preprocessing\n",
        "\n",
        "def split_context(context, left=True):\n",
        "  preprocessing = Preprocessing()\n",
        "  array = preprocessing.word_tok(context)\n",
        "  n = len(array)\n",
        "  half = int(n/2)\n",
        "  if n % 2 == 0:\n",
        "      if left:\n",
        "        return \" \".join(array[:half])\n",
        "      else:\n",
        "        return \" \".join(array[half:])\n",
        "  else:\n",
        "      if left:\n",
        "        return \" \".join(array[:half+1])\n",
        "      else:\n",
        "        return \" \".join(array[half:])\n",
        "\n",
        "def get_date_context(date_no, date_index, n, chunks):\n",
        "  # First date in the sentence\n",
        "  if date_no == 0:\n",
        "    date_context = chunks[date_index-1]\n",
        "    date_context += ' '+chunks[date_index]+' '\n",
        "    date_context += split_context(chunks[date_index+1],left=False)\n",
        "  # Last date in the sentence\n",
        "  elif date_no == n:\n",
        "    date_context = split_context(chunks[date_index-1],left=True)\n",
        "    date_context += ' '+chunks[date_index]+' '\n",
        "    date_context += chunks[date_index+1]\n",
        "  else:\n",
        "    date_context = split_context(chunks[date_index-1],left=True)\n",
        "    date_context += ' '+chunks[date_index]+' '\n",
        "    date_context += split_context(chunks[date_index+1],left=False)\n",
        "  return date_context\n",
        "\n",
        "def get_labeled_phrases(df_docs):\n",
        "  labeled_phrases = []\n",
        "\n",
        "  preprocessing = Preprocessing()\n",
        "  \n",
        "  for doc in df_docs.itertuples():\n",
        "    for sentence in doc.sentences:\n",
        "      # Is there a date in the document?\n",
        "      if re.search(preprocessing.regex_patterns, sentence) is not None:\n",
        "        # Find all the dates\n",
        "        matches_union = preprocessing.regex_patterns.findall(sentence)\n",
        "        # Split the sentence in chunks\n",
        "        # [phrase, date, phrase, date, phrase,...]\n",
        "        chunks = preprocessing.regex_patterns.split(sentence)\n",
        "        # n is the number of dates in the sentence\n",
        "        n = len(matches_union)\n",
        "\n",
        "        # For each date\n",
        "        for date_no, date in enumerate(matches_union):\n",
        "          # Let's convert the date to the appropriate format\n",
        "          normalized_date = preprocessing.date_processing(date.lower())\n",
        "          # Index of the current date in the list of chunks\n",
        "          date_index = 2*date_no+1\n",
        "\n",
        "          # If there is only one date in the sentence,\n",
        "          # the context of the date is the sentence itself\n",
        "          if n == 1:\n",
        "            date_context = sentence\n",
        "          # If there is more than one date in the sentence,\n",
        "          # we keep only the context around each date\n",
        "          else:\n",
        "            date_context = get_date_context(date_no, date_index, n, chunks)\n",
        "          \n",
        "          # Let's remove extra whitespaces\n",
        "          cleaned_date_context = \" \".join(date_context.split())\n",
        "          \n",
        "          # The date is the date of the accident\n",
        "          if normalized_date==doc.accident_date:\n",
        "            labeled_phrases.append({'doc_id':doc.Index,'phrase':cleaned_date_context,'date': normalized_date, 'label': 1})\n",
        "          # The date is the date of the stabilization\n",
        "          elif normalized_date==doc.stabilization_date:\n",
        "            labeled_phrases.append({'doc_id':doc.Index,'phrase':cleaned_date_context,'date': normalized_date, 'label': 2})\n",
        "          # The date is neither the date of the accident nor the date of stabilization\n",
        "          else:\n",
        "            labeled_phrases.append({'doc_id':doc.Index,'phrase':cleaned_date_context,'date': normalized_date,'label': 0})\n",
        "  \n",
        "  return pd.DataFrame(labeled_phrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht-ufi1mOZUc"
      },
      "source": [
        "df_train, df_test = get_labeled_phrases(df_docs_train), get_labeled_phrases(df_docs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kAR8yOSxnNa"
      },
      "source": [
        "## Let's take a look at our data distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbbWh5-QfwKi"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "\n",
        "df_train.label.hist(ax=axs[0],figsize=(10, 5))\n",
        "df_test.label.hist(ax=axs[1],figsize=(10, 5))\n",
        "plt.suptitle('Train & Test Dataset Distribution');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE7wQWU0xufI"
      },
      "source": [
        "## Let's fine-tune CamemBERT (based on Facebook's RoBERTa model, trained on 138GB of French text) to classify our context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xHL1KyOctC"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers==4.6.1\n",
        "!pip install sentencepiece==0.1.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "660RbauHrgCv"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from sklearn import model_selection\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import engine\n",
        "import config\n",
        "from dataset import Dataset\n",
        "from models import CAMEMBERTBase\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "train_dataset = Dataset(\n",
        "    texts=df_train.phrase.values, targets=df_train.label.values\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=2\n",
        ")\n",
        "\n",
        "test_dataset = Dataset(\n",
        "    texts=df_test.phrase.values, targets=df_test.label.values\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=config.TEST_BATCH_SIZE, num_workers=1\n",
        ")\n",
        "\n",
        "device = torch.device(config.DEVICE)\n",
        "model = CAMEMBERTBase()\n",
        "model.to(device)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "\n",
        "num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
        ")\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(df_train.label.values), df_train.label.values)\n",
        "\n",
        "best_mcc = 0\n",
        "for epoch in range(config.EPOCHS):\n",
        "    engine.train_fn(train_data_loader, model, optimizer, device, scheduler, class_weights/sum(class_weights))\n",
        "    outputs_p, targets = engine.eval_fn(test_data_loader, model, device)\n",
        "    outputs = np.argmax(np.array(outputs_p),axis=1)\n",
        "    macro_f1 = metrics.f1_score(targets, outputs, average='macro')\n",
        "    mcc = metrics.matthews_corrcoef(y_true=targets, y_pred=outputs)\n",
        "    print(f\"Macro-F1 Score = {macro_f1}\")\n",
        "    print(f\"mcc Score = {mcc}\")\n",
        "    if mcc > best_mcc:\n",
        "        torch.save(model.state_dict(), config.MODEL_PATH)\n",
        "        best_mcc = mcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqJO6RfAMK-g"
      },
      "source": [
        "## Let's make predictions for the documents in our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkOPD6_O8svG"
      },
      "source": [
        "import config\n",
        "import engine\n",
        "import torch\n",
        "from dataset import Dataset\n",
        "from models import CAMEMBERTBase\n",
        "\n",
        "model = CAMEMBERTBase()\n",
        "model.load_state_dict(torch.load(config.MODEL_PATH,map_location=torch.device(config.DEVICE)))\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OShxruvQ71SG"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def sentence_prediction(model, sentence):\n",
        "  # fetch the tokenizer and max len of tokens from config.py\n",
        "  tokenizer = config.TOKENIZER\n",
        "  max_len = config.MAX_LEN\n",
        "  # the processing is same as it was done for training\n",
        "  sentence = str(sentence)\n",
        "  sentence = \" \".join(sentence.split())\n",
        "  # encode the sentence into ids,\n",
        "  # truncate to max length &\n",
        "  # add CLS and SEP tokens\n",
        "  inputs = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=config.MAX_LEN,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            )\n",
        "  # fetch input ids, mask & token type ids\n",
        "  ids = inputs[\"input_ids\"]\n",
        "  mask = inputs[\"attention_mask\"]\n",
        "  token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "  # convert all the inputs to torch tensors\n",
        "  # we use unsqueeze(0) since we have only one sample\n",
        "  # this makes the batch size 1\n",
        "  ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
        "  mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n",
        "  token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n",
        "  # send everything to device\n",
        "  ids = ids.to('cpu', dtype=torch.long)\n",
        "  token_type_ids = token_type_ids.to('cpu', dtype=torch.long)\n",
        "  mask = mask.to('cpu', dtype=torch.long)\n",
        "  # use the model to make predictions\n",
        "  outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "  logits = outputs[0].cpu().detach().numpy()\n",
        "  return logits\n",
        "  # take sigmoid of prediction and return the output\n",
        "  outputs = torch.softmax(outputs[0],dim=0).cpu().detach().numpy()\n",
        "  print(outputs)\n",
        "  print(np.argmax(outputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j_DjC9RagIl"
      },
      "source": [
        "df_docs_test_labels = df_docs_test[['accident_date','stabilization_date']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ0nYKV7auNu"
      },
      "source": [
        "df_docs_test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeHOO9C_b_Gn"
      },
      "source": [
        "df_test.drop(columns=['label'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP1-UV2qcZ6r"
      },
      "source": [
        "def get_logits(row):\n",
        "  outputs = sentence_prediction(model, row['phrase'])\n",
        "  row['logit_1'] = outputs[1]\n",
        "  row['logit_2'] = outputs[2]\n",
        "  row['pred'] = np.argmax(outputs)\n",
        "  return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAInA3dHbYyA"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o_wWYFsBcXaE"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "df_test = df_test.progress_apply(lambda row: get_logits(row),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j9ryvJ4uAmj"
      },
      "source": [
        "df_accident_date = df_test[df_test.pred == 1].drop(['logit_2','pred'],axis=1)\n",
        "df_accident_date = df_accident_date.groupby(['doc_id','date']).sum()\n",
        "df_accident_date = df_accident_date.iloc[df_accident_date.reset_index().groupby(['doc_id'])['logit_1'].idxmax()]\n",
        "df_accident_date = df_accident_date.drop(columns='logit_1').reset_index().set_index(['doc_id']).rename(columns={\"doc_id\": \"doc_id\", \"date\": \"accident_date\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO1lib2QfmZ7"
      },
      "source": [
        "df_stabilization_date = df_test[df_test.pred == 2].drop(['logit_1','pred'],axis=1)\n",
        "df_stabilization_date = df_stabilization_date.groupby(['doc_id','date']).sum()\n",
        "df_stabilization_date = df_stabilization_date.iloc[df_toto_2.reset_index().groupby(['doc_id'])['logit_2'].idxmax()]\n",
        "df_stabilization_date = df_stabilization_date.drop(columns='logit_2').reset_index().set_index(['doc_id']).rename(columns={\"doc_id\": \"doc_id\", \"date\": \"stabilization_date\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRgEC4Nd4BnC"
      },
      "source": [
        "len(df_docs_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSXISG5o4m-"
      },
      "source": [
        "def compute_overall_accuracy(df_true, df_pred):\n",
        "  score_accident_date = 0\n",
        "  score_stabilization_date = 0\n",
        "\n",
        "  for i in df_pred.index:\n",
        "    if df_true['accident_date'].loc[i] == df_pred['accident_date'].loc[i]:\n",
        "      score_accident_date += 1\n",
        "    if df_true['stabilization_date'].loc[i] == df_pred['stabilization_date'].loc[i]:\n",
        "      score_stabilization_date += 1\n",
        "  \n",
        "  score_accident_date /= len(df_true)\n",
        "  score_stabilization_date /= len(df_true)\n",
        "\n",
        "  print((score_accident_date+score_stabilization_date)/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3971scn4U28"
      },
      "source": [
        "compute_overall_accuracy(df_true=df_docs_test_labels, df_pred=pd.concat([df_toto_1,df_toto_2],axis=1).fillna('n.c.'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}